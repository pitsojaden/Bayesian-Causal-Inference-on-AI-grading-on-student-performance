% Literature Review for: Bayesian Causal Inference on AI Grading Effects on Student Performance

\section{Literature Review}

Understanding the effects of AI grading requires navigating three converging streams of scholarship: the pedagogical validity of automated assessment, the mediating role of student engagement, and the methodological imperative for causal inference.

Research on automated grading has bifurcated into technical validation and user perception studies. Proponents highlight scalability and reliability, with meta-analyses reporting correlation coefficients above 0.80 between human and machine scores for structured tasks \citep{sadasivan2025automated}. Critics counter that such metric-focused evaluations obscure a validity paradox. Systems may reliably score submissions while failing to capture the construct of interest \citep{barrera2025assisting}. This can incentivize surface-level strategies over deep learning. A gap persists in this debate. Studies document that students perceive AI grading with skepticism, a phenomenon termed algorithm aversion \citep{gierl2025implementation}. Few have tested whether such perceptions translate into behavioral changes that alter learning trajectories. Do students disengage when they distrust the grader? This question remains empirically unresolved.

Learning analytics consistently identifies engagement as a driver of academic success. Clickstream data, resource access patterns, and submission timeliness robustly predict final grades \citep{zhang2023learning}. A debate persists, however, regarding the nature of this relationship. Is engagement a stable trait or a dynamic state responsive to assessment cues? \citet{saqr2025engagement} propose the latter. Feedback loops, including grades themselves, actively shape future engagement. In AI grading contexts, this suggests a potential mediation pathway. If automated assessment lowers trust, it may dampen early engagement and cascade into lower performance unrelated to content mastery. Existing predictive models identify these correlations \citep{sha2022predicting}. They fail, however, to isolate the unique contribution of assessment format on engagement dynamics.

The field is undergoing a methodological shift toward causal frameworks. \citet{jivet2021causal} argue that traditional regression models conflate selection bias with treatment effects. High-performing students may naturally engage more, creating spurious associations with grading outcomes. Hierarchical Bayesian methods offer a solution. They accommodate nested data structures and propagate uncertainty, enabling valid inference in observational settings \citep{mosia2025bayesian}. Despite these advances, causal mediation analysis remains underutilized in AI assessment research. Current literature cannot answer a critical policy question. Does AI grading harm students directly through inaccurate scoring? Or does harm occur indirectly by disengaging them from the learning process? This study addresses that gap.
