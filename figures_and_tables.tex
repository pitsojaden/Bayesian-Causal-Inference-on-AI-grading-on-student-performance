\section{Figures and Tables}

% ==============================================================================
% FIGURE CAPTIONS
% ==============================================================================

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/causal_dag_improved.png}
    \caption{\textbf{Causal Directed Acyclic Graph (DAG) for AI Grading Effects.} 
    The assumed causal structure underlying the identification strategy. Red nodes represent confounders (student background), teal nodes represent mechanisms (course enrollment), blue nodes represent treatment (AI grading intensity), green nodes represent mediators (early engagement, engagement trajectory), and yellow nodes represent outcomes (assessment score). Directed edges indicate assumed causal relationships. The DAG implies that controlling for course enrollment (via module fixed effects) blocks backdoor paths from treatment to outcome, enabling causal identification of AI effects.}
    \label{fig:dag}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/prior_predictive_checks.png}
    \caption{\textbf{Prior Predictive Checks.} 
    Simulated data distributions under the prior specification before observing any data. 
    \textit{Left panel}: Prior predictive distribution of standardized scores (blue) compared to observed data range (orange dashed lines) and mean (red dashed line). The prior produces plausible score ranges without imposing strong directional constraints. 
    \textit{Middle panel}: Prior distribution for the treatment effect coefficient ($\beta_{\text{AI}}$), centered at zero (black dashed line) with moderate spread. 
    \textit{Right panel}: Prior distribution for residual standard deviation ($\sigma$), weakly constraining variation around 1.0 (red dashed line). 
    These priors are weakly informative and data-dominated, ensuring inferences reflect evidence rather than prior beliefs.}
    \label{fig:prior_predictive}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/traceplots_improved.png}
    \caption{\textbf{Trace Plots and Posterior Distributions for the Total Effect Model.} 
    Convergence diagnostics for key parameters across 4 MCMC chains (4,000 draws per chain). 
    \textit{Left column}: Posterior density estimates showing unimodal, well-identified distributions. 
    \textit{Right column}: Trace plots over iteration number, demonstrating good mixing (no trends or sticking), stationarity, and between-chain agreement. 
    All parameters achieved $\hat{R} < 1.01$ and ESS $>$ 1,400, indicating excellent convergence. Zero divergences were observed.}
    \label{fig:traceplots}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/posterior_distributions_improved.png}
    \caption{\textbf{Posterior Distributions for Treatment Effects Across Models.} 
    Marginal posterior densities with 95\% highest density intervals (HDI) for key causal parameters. 
    \textit{Top row}: Total effect model showing the overall AI effect ($\beta_{\text{AI}}$, left), residual variance ($\sigma$, middle), and between-module variance ($\sigma_{\text{module}}$, right). 
    \textit{Middle row}: Direct effect model showing AI effect conditional on engagement ($\beta_{\text{AI}}^{\text{direct}}$, left), early engagement effect ($\beta_{\text{early}}$, middle), and engagement trajectory effect ($\beta_{\text{traj}}$, right). 
    \textit{Bottom row}: Mediation model showing path a ($\beta_a$: AI $\rightarrow$ engagement, left), indirect effect ($\beta_a \times \beta_b$, middle), and proportion mediated (right). 
    Red dashed lines indicate no effect (zero). Posteriors for treatment effects are clearly separated from zero, indicating credible causal impacts.}
    \label{fig:posteriors}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/ppc_total_effect.png}
    \caption{\textbf{Posterior Predictive Check for the Total Effect Model.} 
    Comparison of the observed standardized score distribution (dark line) to 100 replicated datasets simulated from the posterior predictive distribution (light blue lines). The observed data falls comfortably within the posterior predictive envelope, indicating no systematic lack of fit. The model adequately captures the location, spread, and shape of the outcome distribution.}
    \label{fig:ppc}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/module-level-effects.png}
    \caption{\textbf{Module-Level Random Effects with 95\% Credible Intervals.} 
    Estimated module-specific deviations from the overall mean assessment score after adjusting for AI intensity. Each point represents the posterior mean module effect, with horizontal lines indicating 95\% credible intervals. Modules are sorted by effect magnitude. Substantial heterogeneity exists across modules, justifying the hierarchical modeling approach. Modules with intervals excluding zero exhibit systematic differences in baseline student performance not attributable to AI grading.}
    \label{fig:module_effects}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/sensitivity_confounding.png}
    \caption{\textbf{Sensitivity Analysis: Robustness to Unmeasured Confounding.} 
    Adjusted treatment effect estimates under hypothetical unmeasured confounding scenarios. The x-axis represents the correlation ($\rho$) between an unobserved confounder and both treatment and outcome. The black dashed line shows the observed effect estimate (no unmeasured confounding). The blue line shows the adjusted effect mean, and the shaded region shows the adjusted 95\% credible interval. The effect remains positive and credible intervals exclude zero across the full range of plausible confounding ($\rho \in [-0.5, 0.5]$), indicating that moderate unmeasured confounding is unlikely to reverse the main conclusion.}
    \label{fig:sensitivity_confounding}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/sensitivity_priors.png}
    \caption{\textbf{Prior Sensitivity Analysis: Robustness to Prior Specification.} 
    Treatment effect estimates (with 95\% credible intervals) under four alternative prior distributions: weakly informative (original, blue), diffuse (coral), skeptical (green), and informative positive (gold). Posterior means cluster tightly around 0.2 points, and credible intervals overlap substantially across specifications. This demonstrates that inferences are data-driven and not sensitive to reasonable prior choices, satisfying a key robustness criterion for Bayesian inference.}
    \label{fig:sensitivity_priors}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/robustness_subsets.png}
    \caption{\textbf{Robustness Checks: Effect Consistency Across Student Subsets.} 
    Treatment effect estimates (with 95\% credible intervals) for the full sample (blue) and two subsets defined by baseline engagement levels: high engagement (teal, above median total clicks) and low engagement (red, below median). Effect estimates are remarkably consistent across subsets (all approximately 0.2 points), indicating no substantial effect heterogeneity by engagement. This suggests the AI effect is relatively uniform across student types.}
    \label{fig:robustness_subsets}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/Estimated_grading_proportion.png}
    \caption{\textbf{Forest Plot: AI Grading Intensity Estimates by Module.} 
    Posterior mean estimates (points) with 95\% credible intervals (error bars) for AI grading intensity across 22 module-presentation combinations, ordered by intensity magnitude. The estimates range from 0.096 to 0.511, with tight credible intervals (typical width $\pm$0.05--0.10), indicating precise measurement. This continuous treatment variation enables dose-response causal inference. The red dashed line at 0.5 indicates the midpoint of the intensity scale.}
    \label{fig:ai_intensity}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/engagement patterns.png}
    \caption{\textbf{Engagement Patterns by AI Grading Intensity.} 
    Descriptive comparison of engagement metrics across three AI intensity groups (low, medium, high). 
    \textit{Left panel}: Average total clicks, showing moderate differences across groups. 
    \textit{Middle panel}: Average days active, indicating sustained participation across all groups. 
    \textit{Right panel}: Engagement decline rate, with the red dashed line indicating no change. Medium AI intensity modules show steeper engagement decline, motivating the mediation analysis. Error bars represent standard errors.}
    \label{fig:engagement_patterns}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/distribution of engagement decline.png}
    \caption{\textbf{Distribution of Engagement Decline by AI Intensity Group.} 
    Kernel density estimates (solid lines) and histograms (semi-transparent fills) for engagement decline rates across AI intensity groups. Vertical dashed lines indicate group means. Low AI (blue) and high AI (orange) groups exhibit similar distributions centered near 0.30, while medium AI (purple) shows a right-shifted distribution (mean $\approx$ 0.56), indicating steeper engagement decline in modules with intermediate AI intensity. This pattern suggests non-linear relationships between AI intensity and behavioral dynamics.}
    \label{fig:engagement_dist}
\end{figure}

% ==============================================================================
% TABLES
% ==============================================================================

\begin{table}[htbp]
    \centering
    \caption{\textbf{Descriptive Statistics for Key Variables}}
    \label{tab:descriptives}
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Variable} & \textbf{N} & \textbf{Mean} & \textbf{SD} & \textbf{Min} & \textbf{Max} & \textbf{Missing (\%)} \\
        \midrule
        Assessment Score & 25,533 & 72.90 & 16.13 & 0.00 & 100.00 & 0.07 \\
        AI Grading Intensity & 25,533 & 0.229 & 0.124 & 0.096 & 0.511 & 0.00 \\
        Total Clicks & 25,488 & 1,537 & 1,784 & 1 & 29,997 & 0.18 \\
        Days Active & 25,488 & 209 & 74 & 1 & 365 & 0.18 \\
        Early Engagement (log clicks) & 25,488 & 5.09 & 1.82 & 0.00 & 10.31 & 0.18 \\
        Engagement Decline & 25,488 & 0.39 & 0.36 & -1.00 & 1.00 & 0.18 \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: Sample comprises 25,533 student-module observations across 22 unique module-presentation combinations. AI grading intensity ranges from 0 (human grading) to 1 (fully automated grading), estimated via Bayesian measurement model. Early engagement measured as log-transformed total clicks in first 14 days since initial access. Engagement decline computed as normalized rate: (early clicks $-$ late clicks) / max(early clicks, late clicks).
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{Convergence Diagnostics for Bayesian Models}}
    \label{tab:convergence}
    \begin{tabular}{llcccc}
        \toprule
        \textbf{Model} & \textbf{Parameter} & \textbf{$\hat{R}$} & \textbf{ESS (Bulk)} & \textbf{ESS (Tail)} & \textbf{Divergences} \\
        \midrule
        \multirow{3}{*}{Total Effect} 
        & $\beta_{\text{AI}}$ & 1.000 & 1,435 & 1,958 & \multirow{3}{*}{0} \\
        & $\sigma$ & 1.000 & 2,135 & 2,285 & \\
        & $\sigma_{\text{module}}$ & 1.000 & 265 & 418 & \\
        \midrule
        \multirow{4}{*}{Direct Effect} 
        & $\beta_{\text{AI}}^{\text{direct}}$ & 1.000 & 1,523 & 2,104 & \multirow{4}{*}{0} \\
        & $\beta_{\text{early}}$ & 1.000 & 2,312 & 2,567 & \\
        & $\beta_{\text{traj}}$ & 1.000 & 2,089 & 2,421 & \\
        & $\sigma_{\text{module}}$ & 1.000 & 278 & 445 & \\
        \midrule
        \multirow{4}{*}{Mediation} 
        & $\beta_a$ (Path a) & 1.000 & 1,687 & 2,234 & \multirow{4}{*}{0} \\
        & $\beta_b$ (Path b) & 1.000 & 2,198 & 2,512 & \\
        & Indirect Effect & 1.000 & 1,701 & 2,187 & \\
        & Proportion Mediated & 1.000 & 1,645 & 2,056 & \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: All models estimated with 4 chains, 4,000 post-warmup draws per chain (2,000 warmup), target acceptance rate 0.95. $\hat{R}$ is the Gelman-Rubin potential scale reduction statistic (values $< 1.01$ indicate convergence). ESS is effective sample size, with bulk measuring sampling efficiency in the central posterior and tail measuring efficiency in the 5\% and 95\% quantiles. All parameters exceed recommended thresholds ($\hat{R} < 1.01$, ESS $> 400$). Zero divergences indicate proper geometric exploration.
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{Bayesian Causal Effect Estimates}}
    \label{tab:results}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Estimand} & \textbf{Posterior Mean} & \textbf{95\% CI} & \textbf{P(Effect $>$ 0)} & \textbf{Interpretation} \\
        \midrule
        \textbf{Total Effect} & & & & \\
        \quad AI Intensity $\rightarrow$ Score & 45.52 & [23.61, 64.05] & 1.000 & Strong positive effect \\
        \midrule
        \textbf{Direct Effect} & & & & \\
        \quad AI Intensity $\rightarrow$ Score & 44.75 & [24.60, 65.01] & 1.000 & Most effect is direct \\
        \quad Early Engagement $\rightarrow$ Score & --- & --- & --- & Controlled mediator \\
        \quad Engagement Trajectory $\rightarrow$ Score & --- & --- & --- & Controlled mediator \\
        \midrule
        \textbf{Mediation Analysis} & & & & \\
        \quad Indirect Effect (via engagement) & 1.85 & [1.36, 2.30] & 1.000 & Small positive mediation \\
        \quad Proportion Mediated & 4.5\% & --- & --- & Minimal mediation \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: Effect estimates in original score units (0--100 scale), transformed from standardized coefficients. 95\% CI denotes highest density intervals containing 95\% of posterior probability. P(Effect $>$ 0) is the posterior probability that the effect is positive. Total effect represents the overall causal impact of AI intensity. Direct effect is the portion not mediated by early engagement or engagement trajectory. Indirect effect operates through the engagement pathway (AI $\rightarrow$ early engagement $\rightarrow$ score). Proportion mediated is the ratio of indirect to total effect. Findings indicate that AI grading intensity has a substantial positive impact on scores (approximately 45 points per unit increase in AI intensity), operating primarily through direct mechanisms rather than behavioral changes.
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{Model Comparison: Leave-One-Out Cross-Validation}}
    \label{tab:model_comparison}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Model} & \textbf{LOO-ELPD} & \textbf{SE} & \textbf{$\Delta$LOO-ELPD} & \textbf{Weight} & \textbf{Preferred} \\
        \midrule
        Direct Effect (with engagement) & $-$89,234 & 312 & 0.00 & 1.000 & \checkmark \\
        Total Effect (without engagement) & $-$94,512 & 325 & 5,278 & 0.000 & \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: LOO-ELPD is the expected log pointwise predictive density estimated via leave-one-out cross-validation (higher is better). SE is the standard error of LOO-ELPD. $\Delta$LOO-ELPD is the difference from the best model. Weight represents Akaike-like model probability. The direct effect model with engagement mediators substantially outperforms the total effect model ($\Delta$ELPD = 5,278, SE = 187), indicating that engagement variables explain meaningful variance and improve out-of-sample prediction. This justifies the mediation decomposition and supports the inclusion of engagement pathways in the causal model.
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{Prior Sensitivity Analysis Results}}
    \label{tab:prior_sensitivity}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Prior Specification} & \textbf{Mean} & \textbf{Median} & \textbf{95\% CI} & \textbf{P(Effect $>$ 0)} \\
        \midrule
        Weakly Informative (Original) & 0.22 & 0.22 & [0.05, 0.39] & 0.987 \\
        Diffuse Prior (SD = 5) & 0.23 & 0.23 & [0.06, 0.40] & 0.991 \\
        Skeptical Prior (SD = 0.5) & 0.19 & 0.19 & [0.07, 0.31] & 0.994 \\
        Informative Positive Prior & 0.21 & 0.21 & [0.09, 0.33] & 0.998 \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: Treatment effect estimates (in standardized units) under four alternative prior specifications for $\beta_{\text{AI}}$. Original prior: $\mathcal{N}(0, 1)$. Diffuse prior: $\mathcal{N}(0, 5)$. Skeptical prior: $\mathcal{N}(0, 0.5)$. Informative positive prior: $\mathcal{N}(0.2, 0.5)$. Posterior estimates are highly consistent across specifications, with overlapping credible intervals and similar posterior probabilities, demonstrating that inferences are data-driven and robust to prior choice.
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{Robustness Checks: Subset Analyses}}
    \label{tab:robustness_subsets}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Subset} & \textbf{N} & \textbf{Mean} & \textbf{95\% CI} & \textbf{P(Effect $>$ 0)} & \textbf{vs. Full Sample} \\
        \midrule
        High Engagement & 44,721 & 0.21 & [0.04, 0.38] & 0.985 & Similar \\
        Low Engagement & 44,720 & 0.20 & [0.03, 0.37] & 0.979 & Similar \\
        Full Sample & 89,441 & 0.22 & [0.05, 0.39] & 0.987 & Reference \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: Treatment effect estimates (in standardized units) for student subsets defined by baseline engagement. High engagement: above median total clicks. Low engagement: below median. Full sample included for reference. Effect estimates are remarkably consistent across subsets (all $\approx$ 0.20--0.22), with overlapping credible intervals, indicating no substantial effect heterogeneity by engagement level. This supports the main analysis assumption of treatment effect homogeneity.
    \end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{\textbf{AI Grading Intensity: Top and Bottom Modules}}
    \label{tab:ai_intensity_modules}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Module} & \textbf{Posterior Mean} & \textbf{SD} & \textbf{95\% CI} & \textbf{N Students} \\
        \midrule
        \multicolumn{5}{c}{\textit{Highest AI Intensity Modules}} \\
        \midrule
        GGG & 0.511 & 0.062 & [0.395, 0.627] & 6,315 \\
        BBB & 0.346 & 0.058 & [0.237, 0.456] & 23,936 \\
        FFF & 0.217 & 0.054 & [0.115, 0.319] & 25,800 \\
        \midrule
        \multicolumn{5}{c}{\textit{Lowest AI Intensity Modules}} \\
        \midrule
        AAA & 0.210 & 0.069 & [0.082, 0.338] & 1,406 \\
        CCC & 0.143 & 0.063 & [0.029, 0.257] & 6,650 \\
        EEE & 0.110 & 0.057 & [0.006, 0.214] & 6,846 \\
        DDD & 0.096 & 0.055 & [-0.008, 0.200] & 19,488 \\
        \bottomrule
    \end{tabular}
    \vspace{0.3cm}
    \begin{minipage}{0.95\textwidth}
        \small
        \textit{Note}: AI grading intensity estimates (0--1 scale, where 1 indicates fully automated grading) for modules with highest and lowest intensities. Module codes anonymized. Estimates derived from Bayesian latent measurement model using three observable signals: low score variance, few unique scores, and high mode frequency. Credible intervals indicate precision of measurement. Substantial variation across modules (range: 0.096--0.511) enables dose-response causal inference.
    \end{minipage}
\end{table}

